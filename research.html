<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
    <link rel="shortcut icon" href="../../docs-assets/ico/favicon.png">
    <title>research</title>

    <!-- Bootstrap core CSS -->
    <link href="assets/css/bootstrap.css" rel="stylesheet">


    <!-- Custom styles for this template -->
    <link href="assets/css/main.css" rel="stylesheet">

    <script src="assets/js/jquery-3.4.1.min.js"></script>
    <script src="assets/js/hover.zoom.js"></script>
    <script src="assets/js/hover.zoom.conf.js"></script>

    <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.3.0/respond.min.js"></script>
    <![endif]-->
	  <script>
		  var _hmt = _hmt || [];
		  (function() {
			  var hm = document.createElement("script");
			  hm.src = "https://hm.baidu.com/hm.js?05af56d0d3a1c2200f9ded78deee94db";
			  var s = document.getElementsByTagName("script")[0];
			  s.parentNode.insertBefore(hm, s);
		  })();
	  </script>

  </head>

  <body>

  <div class="navbar navbar-inverse navbar-static-top">
	  <div class="container">
		  <div class="navbar-header">
			  <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
				  <span class="icon-bar"></span>
				  <span class="icon-bar"></span>
				  <span class="icon-bar"></span>
			  </button>
			  <a class="navbar-brand" href="index.html">Yanchao Sun</a>
		  </div>
		  <div class="navbar-collapse collapse">
			  <ul class="nav navbar-nav navbar-right">
				  <!-- <li><a href="about.html">About me</a></li> -->
				  <li><a href="C.V._of_Yanchao_Sun.pdf">CV</a></li>
				  <li><a href="research.html">Research</a></li>
				  <li><a href="pub.html">Publications</a></li>
				  <!-- <li><a href="project.html">Projects</a></li> -->
				  <li><a href="contact.html">Contact</a></li>
			  </ul>
		  </div><!--/.nav-collapse -->
	  </div>
  </div>


	<!-- +++++ Posts Lists +++++ -->
	<div id="grey">
	    <div class="container">
			<div class="row">
				<div class="col-lg-8 col-lg-offset-2">
					<p><img src="assets/img/user.png" width="50px" height="50px"> <ba>Yanchao Sun</ba></p>
					<p><bd>Jun, 2021 ~ Present</bd></p>
					<h4>Adversarial Attacks and Defenses in Reinforcement Learning.
						<a href="https://arxiv.org/abs/2106.05087">[arXiv link]</a>
					</h4>
					<p> <i>Yanchao Sun, Ruijie Zheng, Yongyuan Liang and Furong Huang</i>
					</p>
					<p>
						Adversarial attacks are studied by a lot of researchers in the field of supervised learning, but are not well-understood in RL, yet. We try to answer the question of "what is the worst-case performance of an RL agent under adversarial attacks" and "how can we improve the certified robustness of RL agents". This is challenging because in RL, the data samples are correlated, and the long-term reward is considered. Traditional attack and defend methods that work well in supervised learning might not work well in RL. <br>
						In this project, we study the essence of adversarial attacks for RL, and propose a novel algorithm that efficiently finds the optimal adversary agains a victim policy. Our proposed algorithm significantly outperforms existing attacking methods. Interestingly, we find that RL agents are extremely vulnerable to our proposed attack method, since we make a well-trained agent totally fail under a small attack radius, even for some agents trained with prior robust training procedures. Applying our proposed attack algorithm to adversarial training, we obtain state-of-the-art robust performance under various strong attacks in MuJoCo and Atari games. 
					</p>
					<!-- <p><a href="research05.html">Read More</a></p> -->
						<!--grants IIS-1526499, and CNS-1626432, and NSFC 61672313.</p>-->
					<!-- <p><a href="research01.html">Read More</a></p> -->
				</div>
			</div><!-- /row -->
	    </div> <!-- /container -->
	</div><!-- /grey -->

	<div id="grey">
	    <div class="container">
			<div class="row">
				<div class="col-lg-8 col-lg-offset-2">
					<p><img src="assets/img/user.png" width="50px" height="50px"> <ba>Yanchao Sun</ba></p>
					<p><bd>April, 2020 ~ Dec, 2020</bd></p>
					<h4>Vulnerability-Aware Poisoning Mechanism for Online RL with Unknown Dynamics. (ICLR 2021)
						<a href="https://openreview.net/pdf?id=9r30XCjf5Dt">[pdf]</a>
					</h4>
					<p> <i>Yanchao Sun, Da Huo and Furong Huang</i>
					</p>
					<p>
						Poisoning attacks, although have been studied extensively in supervised learning, are not well understood in Reinforcement Learning (RL), especially in deep RL. Prior works on poisoning RL usually either assume the attacker knows the underlying Markov Decision Process (MDP), or directly apply the poisoning methods in supervised learning to RL. In this work, we build a generic poisoning framework for online RL via a comprehensive investigation of heterogeneous types/victims of poisoning attacks in RL, considering the unique challenges in RL such as data no longer being i.i.d. Without any prior knowledge of the MDP, we propose a strategic poisoning algorithm called Vulnerability-Aware Adversarial Critic Poison (VA2C-P), which works for most policy-based deep RL agents, using a novel metric, stability radius in RL, that measures the vulnerability of RL algorithms. Experiments on multiple deep RL agents and multiple environments show that our poisoning algorithm successfully prevents agents from learning a good policy, with a limited attacking budget. Our experiment results demonstrate varying vulnerabilities of different deep RL agents in multiple environments, benefiting the understanding and applications of deep RL under security threat scenarios.
					</p>
					<!-- <p><a href="research05.html">Read More</a></p> -->
						<!--grants IIS-1526499, and CNS-1626432, and NSFC 61672313.</p>-->
					<!-- <p><a href="research01.html">Read More</a></p> -->
				</div>
			</div><!-- /row -->
	    </div> <!-- /container -->
	</div><!-- /grey -->

	<div id="grey">
	    <div class="container">
			<div class="row">
				<div class="col-lg-8 col-lg-offset-2">
					<p><img src="assets/img/user.png" width="50px" height="50px"> <ba>Yanchao Sun</ba></p>
					<p><bd>August, 2019 ~ May, 2020</bd></p>
					<h4>Online Multi-task Reinforcement Learning Algorithm. (AAAI 2021)
						<a href="https://arxiv.org/abs/2002.06659">[arXiv link]</a>
					</h4>
					<p> <i>Yanchao Sun, Xiangyu Yin and Furong Huang</i>
					</p>
					<p>
						Online multi-task learning is an important ability for reinforcement learning agents. Existing algorithms usually measure the distances among tasks and attempt to transfer knowledge between similar tasks, but they require the environment space being small, which is not realistic. In contrast, our algorithm borrows knowledge from separate components of multiple previous tasks, so it can be applied to large environment space and work well even the state/action spaces are different. 
					</p>
					<!-- <p><a href="research05.html">Read More</a></p> -->
						<!--grants IIS-1526499, and CNS-1626432, and NSFC 61672313.</p>-->
					<!-- <p><a href="research01.html">Read More</a></p> -->
				</div>
			</div><!-- /row -->
	    </div> <!-- /container -->
	</div><!-- /grey -->

	<div id="grey">
	    <div class="container">
			<div class="row">
				<div class="col-lg-8 col-lg-offset-2">
					<p><img src="assets/img/user.png" width="50px" height="50px"> <ba>Yanchao Sun</ba></p>
					<p><bd>April, 2019 ~ Dec 2019 </bd></p>
					<h4>Can Agents Learn by Analogy? An Inferable Model for PAC Reinforcement Learning. (AAMAS 2020)
						<a href="https://arxiv.org/abs/1912.10329">[arXiv link]</a>
					</h4>
					<p> <i>Yanchao Sun and Furong Huang.</i>
					</p>
					<p>
						<!-- <strong>Abstract </strong> -->
						Model-based reinforcement learning algorithms make decisions by building and utilizing a model of the environment. However, none of the existing algorithms attempts to infer the dynamics of any state-action pair from known state-action pairs before meeting it for sufficient times. We propose a new model-based method called Greedy Inference Model (GIM) that infers the unknown dynamics from known dynamics based on the internal spectral properties of the environment. In other words, GIM can “learn by analogy”. We also propose a new exploration strategy which ensures that the agent rapidly visits unknown state-action pairs. We prove GIM is PAC-MDP, and more computationally efficient as well as more sample efficient (under mild conditions) than state-of-the-art model-based algorithms. Experimental results demon- strate the effectiveness and efficiency of GIM in a variety of real-world tasks.
					</p>
					<!-- <p><a href="research04.html">Read More</a></p> -->
						<!--grants IIS-1526499, and CNS-1626432, and NSFC 61672313.</p>-->
					<!-- <p><a href="research01.html">Read More</a></p> -->
				</div>
			</div><!-- /row -->
	    </div> <!-- /container -->
	</div><!-- /grey -->

	<div id="grey">
	    <div class="container">
			<div class="row">
				<div class="col-lg-8 col-lg-offset-2">
					<p><img src="assets/img/user.png" width="50px" height="50px"> <ba>Yanchao Sun</ba></p>
					<p><bd>January, 2019 ~ Dec 2019</bd></p>
					<h4>Understanding of Generalization in Deep Learning via Tensor Methods. (AISTATS 2020)
						<a href="https://arxiv.org/abs/2001.05070">[arXiv link]</a>
					</h4>
					<p>Jingling Li, Yanchao Sun, Ziyin Liu, Taiji Suzuki and Furong Huang.
					</p>
					<p>
						<!-- <strong>Abstract </strong> -->
						Deep neural networks generalize well on unseen data though the number of parameters often far exceeds the number of training examples. 
						Recently proposed complexity measures have provided insights to understanding the generalizability in neural networks from perspectives of PAC-Bayes, robustness, overparametrization, compression and so on. 
						In this work, we advance the understanding of the relations between the network's architecture and its generalizability from the compression perspective.
						Using tensor analysis, we propose a series of intuitive, data-dependent and easily-measurable properties that tightly characterize the compressibility and generalizability of neural networks; 
						thus, in practice, our generalization bound outperforms the previous compression-based ones, especially for neural networks using tensors as their weight kernels (e.g. CNNs). 
						Moreover, these intuitive measurements provide further insights into designing neural network architectures with properties favorable for better/guaranteed generalizability. 
						Our experimental results demonstrate that through the proposed measurable properties, our generalization error bound matches the trend of the test error well. 
						Our theoretical analysis further provides theoretical justifications for the empirical success and limitations of some widely-used tensor-based compression approaches. 
						We also discover the improvements to the compressibility and robustness of current neural networks when incorporating tensor operations via our proposed layer-wise structure.
					</p>
					<!-- <p><a href="research03.html">Read More</a></p> -->
						<!--grants IIS-1526499, and CNS-1626432, and NSFC 61672313.</p>-->
					<!-- <p><a href="research01.html">Read More</a></p> -->
				</div>
			</div><!-- /row -->
	    </div> <!-- /container -->
	</div><!-- /grey -->

	<div id="grey">
	    <div class="container">
			<div class="row">
				<div class="col-lg-8 col-lg-offset-2">
					<p><img src="assets/img/user.png" width="50px" height="50px"> <ba>Yanchao Sun</ba></p>
					<p><bd>December, 2017 ~ April, 2018</bd></p>
					<h4>Cross-domain Recommendation with Network Embedding.
					</h4>
					<p>Yanchao Sun and Ning Yang
					</p>
					<p>Bachelor Thesis</p>
						<!--grants IIS-1526499, and CNS-1626432, and NSFC 61672313.</p>-->
					<!-- <p><a href="research01.html">Read More</a></p> -->
				</div>
			</div><!-- /row -->
	    </div> <!-- /container -->
	</div><!-- /grey -->

	<div id="grey">
	    <div class="container">
			<div class="row">
				<div class="col-lg-8 col-lg-offset-2">
					<p><img src="assets/img/user.png" width="50px" height="50px"> <ba>Yanchao Sun</ba></p>
					<p><bd>April, 2016 ~ August, 2017</bd></p>
					<h4>Collaborative Inference of Coexisting Information Diﬀusions.
						<a href="https://arxiv.org/abs/1708.06890">[arXiv link]</a>
						<a href="Collaborative Inference of Coexisting Information Diffusions.pdf">[pdf]</a>
					</h4>
					<p>Yanchao Sun, Cong Qian, Ning Yang and Philip S. Yu
					</p>
					<p>published by <a href="http://icdm2017.bigke.org/">the IEEE International Conference on Data Mining (ICDM 2017)</a></p>
					<!--<p>supported by National Science Foundation of China through Grant 61173099, and in part by NSF through-->
						<!--grants IIS-1526499, and CNS-1626432, and NSFC 61672313.</p>-->
					<p><a href="research01.html">Read More</a></p>
				</div>
			</div><!-- /row -->
	    </div> <!-- /container -->
	</div><!-- /grey -->
	
	<div id="white">
	    <div class="container">
			<div class="row">
				<div class="col-lg-8 col-lg-offset-2">
					<p><img src="assets/img/user.png" width="50px" height="50px"> <ba>Yanchao Sun</ba></p>
					<p><bd>March, 2016 ~ November, 2016</bd></p>
					<h4>Modified Linear Time Selection Algorithm <a href="Modified Linear Time Selection Algorithm.pdf">[pdf]</a></h4>
					<p>Yanchao Sun and Yu Chen</p>
					<p><a href="research02.html">Read More</a></p>
				</div>

			</div><!-- /row -->
	    </div> <!-- /container -->
	</div><!-- /white -->

	
	
	<!-- +++++ Footer Section +++++ -->

  <div id="footer">
	  <div class="container">
		  <div class="row" align="center">
			  <div>
				  <h4>Contact me:
				  </h4>
				  <p>
					  Yanchao Sun<br>
                      ycs at cs dot umd dot edu <br> 
				  </p>
			  </div><!-- /col-lg-4 -->
		  </div>

	  </div>
  </div>
	

    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="assets/js/bootstrap.min.js"></script>
  </body>
</html>
